{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.device_count()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, \n",
    "                                      download=True, \n",
    "                                      transform=transforms.ToTensor())\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 3 8 1\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(' '.join(str(classes[labels[j].item()]) for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten the input\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleNet().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(dataloader):\n",
    "    total, correct = 0, 0\n",
    "    for data in dataloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m outputs \u001b[39m=\u001b[39m net(inputs)\n\u001b[1;32m     14\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(outputs, labels)\n\u001b[0;32m---> 15\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     16\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m loss_arr\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_gpu/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_gpu/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_arr = []\n",
    "loss_epoch_arr = []\n",
    "max_epochs = 10\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_arr.append(loss.item())\n",
    "        \n",
    "    loss_epoch_arr.append(loss.item())\n",
    "        \n",
    "    print('Epoch: %d/%d, Test acc: %0.2f, Train acc: %0.2f' % (epoch + 1, max_epochs, evaluation(testloader), evaluation(trainloader)))\n",
    "\n",
    "# Plot the loss\n",
    "plt.plot(loss_epoch_arr)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(p):\n",
    "    return -torch.sum(p * torch.log2(p + 1e-8), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active learning loop\n",
    "max_iterations = 5\n",
    "num_labeled_samples = 1000\n",
    "acquisition_batch_size = 50 # highest uncertainty point in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_indices = np.random.choice(len(trainset), num_labeled_samples, replace=False)\n",
    "unlabeled_indices = list(set(range(len(trainset))) - set(labeled_indices))\n",
    "labeled_dataset = torch.utils.data.Subset(trainset, labeled_indices)\n",
    "unlabeled_dataset = torch.utils.data.Subset(trainset, unlabeled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model = SimpleNet()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Active Learning Iteration 1/5\n"
     ]
    }
   ],
   "source": [
    "# Active learning iterations\n",
    "for iteration in range(max_iterations):\n",
    "    print(f\"\\nActive Learning Iteration {iteration + 1}/{max_iterations}\")\n",
    "\n",
    "    # Calculate model predictions and entropy for the unlabeled dataset\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for data in unlabeled_dataset:\n",
    "            inputs, _ = data\n",
    "            outputs = model(inputs.unsqueeze(0))\n",
    "            predictions.append(outputs.softmax(dim=1))\n",
    "\n",
    "    entropies = entropy(torch.cat(predictions))\n",
    "\n",
    "    # Select the top samples with highest entropy for labeling\n",
    "    top_indices = np.argsort(entropies)[-acquisition_batch_size:]\n",
    "    labeled_indices = np.concatenate((labeled_indices, np.array(unlabeled_indices)[top_indices]))\n",
    "    unlabeled_indices = list(set(unlabeled_indices) - set(np.array(unlabeled_indices)[top_indices]))\n",
    "\n",
    "    # Update labeled and unlabeled datasets\n",
    "    labeled_dataset = torch.utils.data.Subset(trainset, labeled_indices)\n",
    "    unlabeled_dataset = torch.utils.data.Subset(trainset, unlabeled_indices)\n",
    "\n",
    "    # Train the model on the updated labeled dataset\n",
    "    for epoch in range(5):  # Adjust the number of epochs as needed\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    test_accuracy = evaluate_model(model, testloader)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_accuracy = evaluate_model(model, testloader)\n",
    "print(f\"\\nFinal Test Accuracy: {final_test_accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
